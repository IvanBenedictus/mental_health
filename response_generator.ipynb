{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Automatic generation of responses using an LLM**\n",
    "\n",
    "* **Summary:** This notebook is used for generating the responses: response_yes and response_no given the posts from the user. These responses are needed to train the LLM model using Direct Preference Optimization (DPO) approach. The LLM used is model=\"gemini-pro\" from Google.\n",
    "* **Datasets:** addiction_2018_features_tfidf_256.csv from https://zenodo.org/records/3941387\n",
    "* **Contributors:** N Priyanka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain\n",
    "\n",
    "! pip install --upgrade --quiet  langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Google API Key \n",
    "https://makersuite.google.com is the link for generating the API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to securely store your API key\n",
    "from google.colab import userdata\n",
    "\n",
    "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_condition(question):\n",
    "\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables = ['question'],\n",
    "        template = (\"\"\"\n",
    "            Provide me two responses for the question: \"response_yes\" and \"response_no\". Use consistent formatting for the labels.\n",
    "            The response_yes will be the correct evaluation provided as a mental health advisor. \n",
    "            The response_no will be an incorrect evaluation of the query.\n",
    "            While providing response_yes, I want you to act as a mental health adviser. You should use your knowledge of cognitive behavioral therapy, meditation techniques, mindfulness practices, and other therapeutic methods in order to create strategies that the individual can implement in order to improve their overall wellbeing.\n",
    "            In the response_yes, ask them to contact their nearest helpline. Don't provide contact number since you don't know the location of the user.\n",
    "        \"\"\")\n",
    "    )\n",
    "\n",
    "    llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY,temperature=0.2)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    response = chain.run({'question': question})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading The Metal Health Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./source/mental_health.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.DataFrame(df[\"post\"])\n",
    "\n",
    "# Test the first 10 rows\n",
    "posts.iloc[0:11]\n",
    "\n",
    "posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_response = []\n",
    "for post in posts:\n",
    "    response = detect_condition(post)\n",
    "    all_response.append(response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
